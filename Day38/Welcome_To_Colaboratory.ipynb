{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome_To_Colaboratory.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P-H6Lw1vyNNd"
      },
      "source": [
        "# Federated Learning Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imlxcipf_Gj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQZxzSj_IPW",
        "colab_type": "code",
        "outputId": "054104d6-c356-48fd-8c45-e53e54f20eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import syft as sy  # <-- NEW: import the Pysyft library\n",
        "hook = sy.TorchHook(torch)  # <-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning\n",
        "bob = sy.VirtualWorker(hook, id=\"bob\")  # <-- NEW: define remote worker bob\n",
        "alice = sy.VirtualWorker(hook, id=\"alice\")  # <-- NEW: and alice"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0810 16:09:04.909571 140259689711488 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0810 16:09:04.923770 140259689711488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eV0aSjQ_Wl5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI6SAoem_qTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imUlhx2D_sRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Define your network architecture here\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # make sure input tensor is flattened\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.log_softmax(self.fc4(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AKUhbHo_0nX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "#         data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgQ7d6kr_3ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "#             data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJj2ZgC3_6Ue",
        "colab_type": "code",
        "outputId": "0b14d402-a6bf-42f7-c744-38a0d7560535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  import multiprocessing as mp\n",
        "  mp.set_start_method('forkserver', force=True)\n",
        "#   model = Net().to(device)\n",
        "  model = Net()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "  for epoch in range(1, args.epochs + 1):\n",
        "      train(args, model, federated_train_loader, optimizer, epoch)\n",
        "      test(args, model, test_loader)\n",
        "\n",
        "  if (args.save_model):\n",
        "      torch.save(model.state_dict(), \"mnist_cnn.pt\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.322450\n",
            "Train Epoch: 1 [640/60032 (1%)]\tLoss: 2.321743\n",
            "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 2.307015\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.297934\n",
            "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 2.309897\n",
            "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 2.298327\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 2.308297\n",
            "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 2.267097\n",
            "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 2.284019\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 2.282748\n",
            "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 2.295989\n",
            "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 2.262578\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 2.250473\n",
            "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 2.250357\n",
            "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 2.240908\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 2.228352\n",
            "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 2.222480\n",
            "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 2.196472\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 2.201719\n",
            "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 2.180597\n",
            "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 2.160573\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 2.142123\n",
            "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 2.131437\n",
            "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 2.113295\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 2.091141\n",
            "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 2.047172\n",
            "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 2.001865\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 1.971981\n",
            "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 1.942755\n",
            "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 1.906330\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 1.912637\n",
            "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 1.790386\n",
            "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 1.718989\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 1.746202\n",
            "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 1.605489\n",
            "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 1.604300\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 1.518584\n",
            "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 1.333057\n",
            "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 1.381167\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 1.375623\n",
            "Train Epoch: 1 [25600/60032 (43%)]\tLoss: 1.219308\n",
            "Train Epoch: 1 [26240/60032 (44%)]\tLoss: 1.187428\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 1.081985\n",
            "Train Epoch: 1 [27520/60032 (46%)]\tLoss: 1.102653\n",
            "Train Epoch: 1 [28160/60032 (47%)]\tLoss: 0.967017\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 1.058990\n",
            "Train Epoch: 1 [29440/60032 (49%)]\tLoss: 0.927089\n",
            "Train Epoch: 1 [30080/60032 (50%)]\tLoss: 0.844340\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.971155\n",
            "Train Epoch: 1 [31360/60032 (52%)]\tLoss: 0.981789\n",
            "Train Epoch: 1 [32000/60032 (53%)]\tLoss: 0.845401\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.783415\n",
            "Train Epoch: 1 [33280/60032 (55%)]\tLoss: 0.799768\n",
            "Train Epoch: 1 [33920/60032 (57%)]\tLoss: 0.801670\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.655006\n",
            "Train Epoch: 1 [35200/60032 (59%)]\tLoss: 0.718958\n",
            "Train Epoch: 1 [35840/60032 (60%)]\tLoss: 0.821588\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.713043\n",
            "Train Epoch: 1 [37120/60032 (62%)]\tLoss: 0.693551\n",
            "Train Epoch: 1 [37760/60032 (63%)]\tLoss: 0.612926\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.606530\n",
            "Train Epoch: 1 [39040/60032 (65%)]\tLoss: 0.773561\n",
            "Train Epoch: 1 [39680/60032 (66%)]\tLoss: 0.739478\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.648156\n",
            "Train Epoch: 1 [40960/60032 (68%)]\tLoss: 0.692474\n",
            "Train Epoch: 1 [41600/60032 (69%)]\tLoss: 0.709458\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.675662\n",
            "Train Epoch: 1 [42880/60032 (71%)]\tLoss: 0.692351\n",
            "Train Epoch: 1 [43520/60032 (72%)]\tLoss: 0.502925\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.602054\n",
            "Train Epoch: 1 [44800/60032 (75%)]\tLoss: 0.693393\n",
            "Train Epoch: 1 [45440/60032 (76%)]\tLoss: 0.510419\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.531155\n",
            "Train Epoch: 1 [46720/60032 (78%)]\tLoss: 0.503150\n",
            "Train Epoch: 1 [47360/60032 (79%)]\tLoss: 0.580450\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.569276\n",
            "Train Epoch: 1 [48640/60032 (81%)]\tLoss: 0.420627\n",
            "Train Epoch: 1 [49280/60032 (82%)]\tLoss: 0.450105\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.271807\n",
            "Train Epoch: 1 [50560/60032 (84%)]\tLoss: 0.695120\n",
            "Train Epoch: 1 [51200/60032 (85%)]\tLoss: 0.545043\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.579340\n",
            "Train Epoch: 1 [52480/60032 (87%)]\tLoss: 0.366507\n",
            "Train Epoch: 1 [53120/60032 (88%)]\tLoss: 0.358980\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.439596\n",
            "Train Epoch: 1 [54400/60032 (91%)]\tLoss: 0.434636\n",
            "Train Epoch: 1 [55040/60032 (92%)]\tLoss: 0.876318\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.452707\n",
            "Train Epoch: 1 [56320/60032 (94%)]\tLoss: 0.427281\n",
            "Train Epoch: 1 [56960/60032 (95%)]\tLoss: 0.526709\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.296378\n",
            "Train Epoch: 1 [58240/60032 (97%)]\tLoss: 0.214989\n",
            "Train Epoch: 1 [58880/60032 (98%)]\tLoss: 0.387039\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.387033\n",
            "\n",
            "Test set: Average loss: 0.4256, Accuracy: 8757/10000 (88%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.510109\n",
            "Train Epoch: 2 [640/60032 (1%)]\tLoss: 0.437931\n",
            "Train Epoch: 2 [1280/60032 (2%)]\tLoss: 0.341414\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.634767\n",
            "Train Epoch: 2 [2560/60032 (4%)]\tLoss: 0.420433\n",
            "Train Epoch: 2 [3200/60032 (5%)]\tLoss: 0.373781\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.588157\n",
            "Train Epoch: 2 [4480/60032 (7%)]\tLoss: 0.443748\n",
            "Train Epoch: 2 [5120/60032 (9%)]\tLoss: 0.332913\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.284262\n",
            "Train Epoch: 2 [6400/60032 (11%)]\tLoss: 0.531324\n",
            "Train Epoch: 2 [7040/60032 (12%)]\tLoss: 0.557631\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.399070\n",
            "Train Epoch: 2 [8320/60032 (14%)]\tLoss: 0.456126\n",
            "Train Epoch: 2 [8960/60032 (15%)]\tLoss: 0.324532\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.401662\n",
            "Train Epoch: 2 [10240/60032 (17%)]\tLoss: 0.452428\n",
            "Train Epoch: 2 [10880/60032 (18%)]\tLoss: 0.435860\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.486544\n",
            "Train Epoch: 2 [12160/60032 (20%)]\tLoss: 0.454786\n",
            "Train Epoch: 2 [12800/60032 (21%)]\tLoss: 0.309765\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.328081\n",
            "Train Epoch: 2 [14080/60032 (23%)]\tLoss: 0.432178\n",
            "Train Epoch: 2 [14720/60032 (25%)]\tLoss: 0.536417\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.512079\n",
            "Train Epoch: 2 [16000/60032 (27%)]\tLoss: 0.467001\n",
            "Train Epoch: 2 [16640/60032 (28%)]\tLoss: 0.405970\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.390804\n",
            "Train Epoch: 2 [17920/60032 (30%)]\tLoss: 0.307876\n",
            "Train Epoch: 2 [18560/60032 (31%)]\tLoss: 0.441070\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.298707\n",
            "Train Epoch: 2 [19840/60032 (33%)]\tLoss: 0.324616\n",
            "Train Epoch: 2 [20480/60032 (34%)]\tLoss: 0.390227\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.409169\n",
            "Train Epoch: 2 [21760/60032 (36%)]\tLoss: 0.284221\n",
            "Train Epoch: 2 [22400/60032 (37%)]\tLoss: 0.365478\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.406034\n",
            "Train Epoch: 2 [23680/60032 (39%)]\tLoss: 0.227879\n",
            "Train Epoch: 2 [24320/60032 (41%)]\tLoss: 0.355728\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.414185\n",
            "Train Epoch: 2 [25600/60032 (43%)]\tLoss: 0.386585\n",
            "Train Epoch: 2 [26240/60032 (44%)]\tLoss: 0.460936\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.311508\n",
            "Train Epoch: 2 [27520/60032 (46%)]\tLoss: 0.333957\n",
            "Train Epoch: 2 [28160/60032 (47%)]\tLoss: 0.409043\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.424159\n",
            "Train Epoch: 2 [29440/60032 (49%)]\tLoss: 0.455379\n",
            "Train Epoch: 2 [30080/60032 (50%)]\tLoss: 0.229390\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.367178\n",
            "Train Epoch: 2 [31360/60032 (52%)]\tLoss: 0.729156\n",
            "Train Epoch: 2 [32000/60032 (53%)]\tLoss: 0.327974\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.205664\n",
            "Train Epoch: 2 [33280/60032 (55%)]\tLoss: 0.296330\n",
            "Train Epoch: 2 [33920/60032 (57%)]\tLoss: 0.219526\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.359953\n",
            "Train Epoch: 2 [35200/60032 (59%)]\tLoss: 0.168748\n",
            "Train Epoch: 2 [35840/60032 (60%)]\tLoss: 0.447587\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.279088\n",
            "Train Epoch: 2 [37120/60032 (62%)]\tLoss: 0.318315\n",
            "Train Epoch: 2 [37760/60032 (63%)]\tLoss: 0.413621\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.309507\n",
            "Train Epoch: 2 [39040/60032 (65%)]\tLoss: 0.215949\n",
            "Train Epoch: 2 [39680/60032 (66%)]\tLoss: 0.310275\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.172715\n",
            "Train Epoch: 2 [40960/60032 (68%)]\tLoss: 0.381459\n",
            "Train Epoch: 2 [41600/60032 (69%)]\tLoss: 0.303487\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.184679\n",
            "Train Epoch: 2 [42880/60032 (71%)]\tLoss: 0.232027\n",
            "Train Epoch: 2 [43520/60032 (72%)]\tLoss: 0.170663\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.781209\n",
            "Train Epoch: 2 [44800/60032 (75%)]\tLoss: 0.252733\n",
            "Train Epoch: 2 [45440/60032 (76%)]\tLoss: 0.198120\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.356889\n",
            "Train Epoch: 2 [46720/60032 (78%)]\tLoss: 0.450210\n",
            "Train Epoch: 2 [47360/60032 (79%)]\tLoss: 0.163872\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.448911\n",
            "Train Epoch: 2 [48640/60032 (81%)]\tLoss: 0.340057\n",
            "Train Epoch: 2 [49280/60032 (82%)]\tLoss: 0.248818\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.385377\n",
            "Train Epoch: 2 [50560/60032 (84%)]\tLoss: 0.270580\n",
            "Train Epoch: 2 [51200/60032 (85%)]\tLoss: 0.225180\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.229006\n",
            "Train Epoch: 2 [52480/60032 (87%)]\tLoss: 0.345902\n",
            "Train Epoch: 2 [53120/60032 (88%)]\tLoss: 0.333685\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.363657\n",
            "Train Epoch: 2 [54400/60032 (91%)]\tLoss: 0.303834\n",
            "Train Epoch: 2 [55040/60032 (92%)]\tLoss: 0.287286\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.458413\n",
            "Train Epoch: 2 [56320/60032 (94%)]\tLoss: 0.681503\n",
            "Train Epoch: 2 [56960/60032 (95%)]\tLoss: 0.378122\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.233966\n",
            "Train Epoch: 2 [58240/60032 (97%)]\tLoss: 0.390999\n",
            "Train Epoch: 2 [58880/60032 (98%)]\tLoss: 0.113586\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.304224\n",
            "\n",
            "Test set: Average loss: 0.2821, Accuracy: 9181/10000 (92%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.318261\n",
            "Train Epoch: 3 [640/60032 (1%)]\tLoss: 0.252411\n",
            "Train Epoch: 3 [1280/60032 (2%)]\tLoss: 0.497956\n",
            "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.258551\n",
            "Train Epoch: 3 [2560/60032 (4%)]\tLoss: 0.288499\n",
            "Train Epoch: 3 [3200/60032 (5%)]\tLoss: 0.370508\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.328526\n",
            "Train Epoch: 3 [4480/60032 (7%)]\tLoss: 0.169604\n",
            "Train Epoch: 3 [5120/60032 (9%)]\tLoss: 0.184648\n",
            "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.295646\n",
            "Train Epoch: 3 [6400/60032 (11%)]\tLoss: 0.462424\n",
            "Train Epoch: 3 [7040/60032 (12%)]\tLoss: 0.357419\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.151324\n",
            "Train Epoch: 3 [8320/60032 (14%)]\tLoss: 0.394202\n",
            "Train Epoch: 3 [8960/60032 (15%)]\tLoss: 0.142455\n",
            "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.305472\n",
            "Train Epoch: 3 [10240/60032 (17%)]\tLoss: 0.300724\n",
            "Train Epoch: 3 [10880/60032 (18%)]\tLoss: 0.189243\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.303169\n",
            "Train Epoch: 3 [12160/60032 (20%)]\tLoss: 0.203433\n",
            "Train Epoch: 3 [12800/60032 (21%)]\tLoss: 0.249370\n",
            "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.371691\n",
            "Train Epoch: 3 [14080/60032 (23%)]\tLoss: 0.233562\n",
            "Train Epoch: 3 [14720/60032 (25%)]\tLoss: 0.273951\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.327506\n",
            "Train Epoch: 3 [16000/60032 (27%)]\tLoss: 0.397011\n",
            "Train Epoch: 3 [16640/60032 (28%)]\tLoss: 0.270725\n",
            "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.248284\n",
            "Train Epoch: 3 [17920/60032 (30%)]\tLoss: 0.174701\n",
            "Train Epoch: 3 [18560/60032 (31%)]\tLoss: 0.436918\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.194199\n",
            "Train Epoch: 3 [19840/60032 (33%)]\tLoss: 0.234963\n",
            "Train Epoch: 3 [20480/60032 (34%)]\tLoss: 0.306665\n",
            "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.431520\n",
            "Train Epoch: 3 [21760/60032 (36%)]\tLoss: 0.218619\n",
            "Train Epoch: 3 [22400/60032 (37%)]\tLoss: 0.196848\n",
            "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.326523\n",
            "Train Epoch: 3 [23680/60032 (39%)]\tLoss: 0.313054\n",
            "Train Epoch: 3 [24320/60032 (41%)]\tLoss: 0.194950\n",
            "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.287553\n",
            "Train Epoch: 3 [25600/60032 (43%)]\tLoss: 0.171812\n",
            "Train Epoch: 3 [26240/60032 (44%)]\tLoss: 0.310164\n",
            "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.217971\n",
            "Train Epoch: 3 [27520/60032 (46%)]\tLoss: 0.207560\n",
            "Train Epoch: 3 [28160/60032 (47%)]\tLoss: 0.257853\n",
            "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.182416\n",
            "Train Epoch: 3 [29440/60032 (49%)]\tLoss: 0.614215\n",
            "Train Epoch: 3 [30080/60032 (50%)]\tLoss: 0.233701\n",
            "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.238438\n",
            "Train Epoch: 3 [31360/60032 (52%)]\tLoss: 0.209295\n",
            "Train Epoch: 3 [32000/60032 (53%)]\tLoss: 0.122714\n",
            "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.094965\n",
            "Train Epoch: 3 [33280/60032 (55%)]\tLoss: 0.315682\n",
            "Train Epoch: 3 [33920/60032 (57%)]\tLoss: 0.158396\n",
            "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.099970\n",
            "Train Epoch: 3 [35200/60032 (59%)]\tLoss: 0.201921\n",
            "Train Epoch: 3 [35840/60032 (60%)]\tLoss: 0.140738\n",
            "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.319726\n",
            "Train Epoch: 3 [37120/60032 (62%)]\tLoss: 0.217489\n",
            "Train Epoch: 3 [37760/60032 (63%)]\tLoss: 0.225823\n",
            "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.376057\n",
            "Train Epoch: 3 [39040/60032 (65%)]\tLoss: 0.200834\n",
            "Train Epoch: 3 [39680/60032 (66%)]\tLoss: 0.440856\n",
            "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.179701\n",
            "Train Epoch: 3 [40960/60032 (68%)]\tLoss: 0.184343\n",
            "Train Epoch: 3 [41600/60032 (69%)]\tLoss: 0.173871\n",
            "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.453257\n",
            "Train Epoch: 3 [42880/60032 (71%)]\tLoss: 0.349325\n",
            "Train Epoch: 3 [43520/60032 (72%)]\tLoss: 0.250890\n",
            "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.173900\n",
            "Train Epoch: 3 [44800/60032 (75%)]\tLoss: 0.182065\n",
            "Train Epoch: 3 [45440/60032 (76%)]\tLoss: 0.231136\n",
            "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.109120\n",
            "Train Epoch: 3 [46720/60032 (78%)]\tLoss: 0.230702\n",
            "Train Epoch: 3 [47360/60032 (79%)]\tLoss: 0.165402\n",
            "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.236479\n",
            "Train Epoch: 3 [48640/60032 (81%)]\tLoss: 0.271442\n",
            "Train Epoch: 3 [49280/60032 (82%)]\tLoss: 0.191107\n",
            "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.118728\n",
            "Train Epoch: 3 [50560/60032 (84%)]\tLoss: 0.217412\n",
            "Train Epoch: 3 [51200/60032 (85%)]\tLoss: 0.185442\n",
            "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.169793\n",
            "Train Epoch: 3 [52480/60032 (87%)]\tLoss: 0.257259\n",
            "Train Epoch: 3 [53120/60032 (88%)]\tLoss: 0.247932\n",
            "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.167983\n",
            "Train Epoch: 3 [54400/60032 (91%)]\tLoss: 0.167097\n",
            "Train Epoch: 3 [55040/60032 (92%)]\tLoss: 0.390301\n",
            "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.303819\n",
            "Train Epoch: 3 [56320/60032 (94%)]\tLoss: 0.196722\n",
            "Train Epoch: 3 [56960/60032 (95%)]\tLoss: 0.138711\n",
            "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.298431\n",
            "Train Epoch: 3 [58240/60032 (97%)]\tLoss: 0.177014\n",
            "Train Epoch: 3 [58880/60032 (98%)]\tLoss: 0.223843\n",
            "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.285847\n",
            "\n",
            "Test set: Average loss: 0.2280, Accuracy: 9327/10000 (93%)\n",
            "\n",
            "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.163288\n",
            "Train Epoch: 4 [640/60032 (1%)]\tLoss: 0.167137\n",
            "Train Epoch: 4 [1280/60032 (2%)]\tLoss: 0.281148\n",
            "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.322370\n",
            "Train Epoch: 4 [2560/60032 (4%)]\tLoss: 0.214719\n",
            "Train Epoch: 4 [3200/60032 (5%)]\tLoss: 0.217531\n",
            "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.327620\n",
            "Train Epoch: 4 [4480/60032 (7%)]\tLoss: 0.202118\n",
            "Train Epoch: 4 [5120/60032 (9%)]\tLoss: 0.165798\n",
            "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.212701\n",
            "Train Epoch: 4 [6400/60032 (11%)]\tLoss: 0.163542\n",
            "Train Epoch: 4 [7040/60032 (12%)]\tLoss: 0.494010\n",
            "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.187930\n",
            "Train Epoch: 4 [8320/60032 (14%)]\tLoss: 0.132828\n",
            "Train Epoch: 4 [8960/60032 (15%)]\tLoss: 0.217242\n",
            "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.320142\n",
            "Train Epoch: 4 [10240/60032 (17%)]\tLoss: 0.360951\n",
            "Train Epoch: 4 [10880/60032 (18%)]\tLoss: 0.336345\n",
            "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.120710\n",
            "Train Epoch: 4 [12160/60032 (20%)]\tLoss: 0.352631\n",
            "Train Epoch: 4 [12800/60032 (21%)]\tLoss: 0.234086\n",
            "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.402546\n",
            "Train Epoch: 4 [14080/60032 (23%)]\tLoss: 0.289471\n",
            "Train Epoch: 4 [14720/60032 (25%)]\tLoss: 0.130821\n",
            "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.246774\n",
            "Train Epoch: 4 [16000/60032 (27%)]\tLoss: 0.161280\n",
            "Train Epoch: 4 [16640/60032 (28%)]\tLoss: 0.169658\n",
            "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.111728\n",
            "Train Epoch: 4 [17920/60032 (30%)]\tLoss: 0.165212\n",
            "Train Epoch: 4 [18560/60032 (31%)]\tLoss: 0.310713\n",
            "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.320531\n",
            "Train Epoch: 4 [19840/60032 (33%)]\tLoss: 0.319980\n",
            "Train Epoch: 4 [20480/60032 (34%)]\tLoss: 0.211145\n",
            "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.164087\n",
            "Train Epoch: 4 [21760/60032 (36%)]\tLoss: 0.218009\n",
            "Train Epoch: 4 [22400/60032 (37%)]\tLoss: 0.264455\n",
            "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.108001\n",
            "Train Epoch: 4 [23680/60032 (39%)]\tLoss: 0.223717\n",
            "Train Epoch: 4 [24320/60032 (41%)]\tLoss: 0.100518\n",
            "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.339705\n",
            "Train Epoch: 4 [25600/60032 (43%)]\tLoss: 0.296666\n",
            "Train Epoch: 4 [26240/60032 (44%)]\tLoss: 0.298316\n",
            "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.205283\n",
            "Train Epoch: 4 [27520/60032 (46%)]\tLoss: 0.405753\n",
            "Train Epoch: 4 [28160/60032 (47%)]\tLoss: 0.182045\n",
            "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.323898\n",
            "Train Epoch: 4 [29440/60032 (49%)]\tLoss: 0.179763\n",
            "Train Epoch: 4 [30080/60032 (50%)]\tLoss: 0.331470\n",
            "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.068586\n",
            "Train Epoch: 4 [31360/60032 (52%)]\tLoss: 0.198877\n",
            "Train Epoch: 4 [32000/60032 (53%)]\tLoss: 0.286113\n",
            "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.221358\n",
            "Train Epoch: 4 [33280/60032 (55%)]\tLoss: 0.219206\n",
            "Train Epoch: 4 [33920/60032 (57%)]\tLoss: 0.192626\n",
            "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.103214\n",
            "Train Epoch: 4 [35200/60032 (59%)]\tLoss: 0.206340\n",
            "Train Epoch: 4 [35840/60032 (60%)]\tLoss: 0.320180\n",
            "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.232005\n",
            "Train Epoch: 4 [37120/60032 (62%)]\tLoss: 0.218275\n",
            "Train Epoch: 4 [37760/60032 (63%)]\tLoss: 0.183050\n",
            "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.122270\n",
            "Train Epoch: 4 [39040/60032 (65%)]\tLoss: 0.044410\n",
            "Train Epoch: 4 [39680/60032 (66%)]\tLoss: 0.159650\n",
            "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.125367\n",
            "Train Epoch: 4 [40960/60032 (68%)]\tLoss: 0.170545\n",
            "Train Epoch: 4 [41600/60032 (69%)]\tLoss: 0.174235\n",
            "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.202146\n",
            "Train Epoch: 4 [42880/60032 (71%)]\tLoss: 0.161618\n",
            "Train Epoch: 4 [43520/60032 (72%)]\tLoss: 0.249092\n",
            "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.161268\n",
            "Train Epoch: 4 [44800/60032 (75%)]\tLoss: 0.129465\n",
            "Train Epoch: 4 [45440/60032 (76%)]\tLoss: 0.144592\n",
            "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.253637\n",
            "Train Epoch: 4 [46720/60032 (78%)]\tLoss: 0.192453\n",
            "Train Epoch: 4 [47360/60032 (79%)]\tLoss: 0.250328\n",
            "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.219232\n",
            "Train Epoch: 4 [48640/60032 (81%)]\tLoss: 0.237378\n",
            "Train Epoch: 4 [49280/60032 (82%)]\tLoss: 0.498477\n",
            "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.135433\n",
            "Train Epoch: 4 [50560/60032 (84%)]\tLoss: 0.306934\n",
            "Train Epoch: 4 [51200/60032 (85%)]\tLoss: 0.168459\n",
            "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.288606\n",
            "Train Epoch: 4 [52480/60032 (87%)]\tLoss: 0.190713\n",
            "Train Epoch: 4 [53120/60032 (88%)]\tLoss: 0.091384\n",
            "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.208479\n",
            "Train Epoch: 4 [54400/60032 (91%)]\tLoss: 0.127544\n",
            "Train Epoch: 4 [55040/60032 (92%)]\tLoss: 0.133989\n",
            "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.185979\n",
            "Train Epoch: 4 [56320/60032 (94%)]\tLoss: 0.145559\n",
            "Train Epoch: 4 [56960/60032 (95%)]\tLoss: 0.184293\n",
            "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.194141\n",
            "Train Epoch: 4 [58240/60032 (97%)]\tLoss: 0.186777\n",
            "Train Epoch: 4 [58880/60032 (98%)]\tLoss: 0.151998\n",
            "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.248182\n",
            "\n",
            "Test set: Average loss: 0.1864, Accuracy: 9456/10000 (95%)\n",
            "\n",
            "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.144684\n",
            "Train Epoch: 5 [640/60032 (1%)]\tLoss: 0.386415\n",
            "Train Epoch: 5 [1280/60032 (2%)]\tLoss: 0.239423\n",
            "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.251599\n",
            "Train Epoch: 5 [2560/60032 (4%)]\tLoss: 0.201420\n",
            "Train Epoch: 5 [3200/60032 (5%)]\tLoss: 0.271647\n",
            "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.186945\n",
            "Train Epoch: 5 [4480/60032 (7%)]\tLoss: 0.158739\n",
            "Train Epoch: 5 [5120/60032 (9%)]\tLoss: 0.185690\n",
            "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.472866\n",
            "Train Epoch: 5 [6400/60032 (11%)]\tLoss: 0.128221\n",
            "Train Epoch: 5 [7040/60032 (12%)]\tLoss: 0.184753\n",
            "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.201783\n",
            "Train Epoch: 5 [8320/60032 (14%)]\tLoss: 0.209657\n",
            "Train Epoch: 5 [8960/60032 (15%)]\tLoss: 0.192196\n",
            "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.167208\n",
            "Train Epoch: 5 [10240/60032 (17%)]\tLoss: 0.372080\n",
            "Train Epoch: 5 [10880/60032 (18%)]\tLoss: 0.259251\n",
            "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.085016\n",
            "Train Epoch: 5 [12160/60032 (20%)]\tLoss: 0.183132\n",
            "Train Epoch: 5 [12800/60032 (21%)]\tLoss: 0.140824\n",
            "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.225163\n",
            "Train Epoch: 5 [14080/60032 (23%)]\tLoss: 0.105605\n",
            "Train Epoch: 5 [14720/60032 (25%)]\tLoss: 0.126170\n",
            "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.222696\n",
            "Train Epoch: 5 [16000/60032 (27%)]\tLoss: 0.085509\n",
            "Train Epoch: 5 [16640/60032 (28%)]\tLoss: 0.212638\n",
            "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.206092\n",
            "Train Epoch: 5 [17920/60032 (30%)]\tLoss: 0.096099\n",
            "Train Epoch: 5 [18560/60032 (31%)]\tLoss: 0.171212\n",
            "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.210684\n",
            "Train Epoch: 5 [19840/60032 (33%)]\tLoss: 0.177239\n",
            "Train Epoch: 5 [20480/60032 (34%)]\tLoss: 0.313414\n",
            "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.208896\n",
            "Train Epoch: 5 [21760/60032 (36%)]\tLoss: 0.073271\n",
            "Train Epoch: 5 [22400/60032 (37%)]\tLoss: 0.119722\n",
            "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.286215\n",
            "Train Epoch: 5 [23680/60032 (39%)]\tLoss: 0.256534\n",
            "Train Epoch: 5 [24320/60032 (41%)]\tLoss: 0.127355\n",
            "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.199783\n",
            "Train Epoch: 5 [25600/60032 (43%)]\tLoss: 0.194916\n",
            "Train Epoch: 5 [26240/60032 (44%)]\tLoss: 0.090294\n",
            "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.239555\n",
            "Train Epoch: 5 [27520/60032 (46%)]\tLoss: 0.156637\n",
            "Train Epoch: 5 [28160/60032 (47%)]\tLoss: 0.230713\n",
            "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.272793\n",
            "Train Epoch: 5 [29440/60032 (49%)]\tLoss: 0.077554\n",
            "Train Epoch: 5 [30080/60032 (50%)]\tLoss: 0.233218\n",
            "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.309530\n",
            "Train Epoch: 5 [31360/60032 (52%)]\tLoss: 0.200405\n",
            "Train Epoch: 5 [32000/60032 (53%)]\tLoss: 0.147824\n",
            "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.165233\n",
            "Train Epoch: 5 [33280/60032 (55%)]\tLoss: 0.151673\n",
            "Train Epoch: 5 [33920/60032 (57%)]\tLoss: 0.201416\n",
            "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.085557\n",
            "Train Epoch: 5 [35200/60032 (59%)]\tLoss: 0.103684\n",
            "Train Epoch: 5 [35840/60032 (60%)]\tLoss: 0.118839\n",
            "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.158894\n",
            "Train Epoch: 5 [37120/60032 (62%)]\tLoss: 0.122838\n",
            "Train Epoch: 5 [37760/60032 (63%)]\tLoss: 0.144108\n",
            "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.065674\n",
            "Train Epoch: 5 [39040/60032 (65%)]\tLoss: 0.180749\n",
            "Train Epoch: 5 [39680/60032 (66%)]\tLoss: 0.218831\n",
            "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.104450\n",
            "Train Epoch: 5 [40960/60032 (68%)]\tLoss: 0.326188\n",
            "Train Epoch: 5 [41600/60032 (69%)]\tLoss: 0.144919\n",
            "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.212960\n",
            "Train Epoch: 5 [42880/60032 (71%)]\tLoss: 0.174427\n",
            "Train Epoch: 5 [43520/60032 (72%)]\tLoss: 0.233880\n",
            "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.120398\n",
            "Train Epoch: 5 [44800/60032 (75%)]\tLoss: 0.125456\n",
            "Train Epoch: 5 [45440/60032 (76%)]\tLoss: 0.053159\n",
            "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.097991\n",
            "Train Epoch: 5 [46720/60032 (78%)]\tLoss: 0.056398\n",
            "Train Epoch: 5 [47360/60032 (79%)]\tLoss: 0.114721\n",
            "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.186799\n",
            "Train Epoch: 5 [48640/60032 (81%)]\tLoss: 0.207946\n",
            "Train Epoch: 5 [49280/60032 (82%)]\tLoss: 0.150941\n",
            "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.105991\n",
            "Train Epoch: 5 [50560/60032 (84%)]\tLoss: 0.163078\n",
            "Train Epoch: 5 [51200/60032 (85%)]\tLoss: 0.074968\n",
            "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.331655\n",
            "Train Epoch: 5 [52480/60032 (87%)]\tLoss: 0.353157\n",
            "Train Epoch: 5 [53120/60032 (88%)]\tLoss: 0.085301\n",
            "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.140904\n",
            "Train Epoch: 5 [54400/60032 (91%)]\tLoss: 0.400745\n",
            "Train Epoch: 5 [55040/60032 (92%)]\tLoss: 0.294874\n",
            "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.086971\n",
            "Train Epoch: 5 [56320/60032 (94%)]\tLoss: 0.275917\n",
            "Train Epoch: 5 [56960/60032 (95%)]\tLoss: 0.085019\n",
            "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.063843\n",
            "Train Epoch: 5 [58240/60032 (97%)]\tLoss: 0.198725\n",
            "Train Epoch: 5 [58880/60032 (98%)]\tLoss: 0.108408\n",
            "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.037370\n",
            "\n",
            "Test set: Average loss: 0.1647, Accuracy: 9518/10000 (95%)\n",
            "\n",
            "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.107958\n",
            "Train Epoch: 6 [640/60032 (1%)]\tLoss: 0.139644\n",
            "Train Epoch: 6 [1280/60032 (2%)]\tLoss: 0.287206\n",
            "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.165356\n",
            "Train Epoch: 6 [2560/60032 (4%)]\tLoss: 0.084601\n",
            "Train Epoch: 6 [3200/60032 (5%)]\tLoss: 0.097256\n",
            "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.256248\n",
            "Train Epoch: 6 [4480/60032 (7%)]\tLoss: 0.115869\n",
            "Train Epoch: 6 [5120/60032 (9%)]\tLoss: 0.187469\n",
            "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.097170\n",
            "Train Epoch: 6 [6400/60032 (11%)]\tLoss: 0.125568\n",
            "Train Epoch: 6 [7040/60032 (12%)]\tLoss: 0.127430\n",
            "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.172247\n",
            "Train Epoch: 6 [8320/60032 (14%)]\tLoss: 0.161586\n",
            "Train Epoch: 6 [8960/60032 (15%)]\tLoss: 0.170113\n",
            "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.112815\n",
            "Train Epoch: 6 [10240/60032 (17%)]\tLoss: 0.137791\n",
            "Train Epoch: 6 [10880/60032 (18%)]\tLoss: 0.130217\n",
            "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.212529\n",
            "Train Epoch: 6 [12160/60032 (20%)]\tLoss: 0.092375\n",
            "Train Epoch: 6 [12800/60032 (21%)]\tLoss: 0.140938\n",
            "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.339468\n",
            "Train Epoch: 6 [14080/60032 (23%)]\tLoss: 0.122448\n",
            "Train Epoch: 6 [14720/60032 (25%)]\tLoss: 0.149248\n",
            "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.260180\n",
            "Train Epoch: 6 [16000/60032 (27%)]\tLoss: 0.074075\n",
            "Train Epoch: 6 [16640/60032 (28%)]\tLoss: 0.112498\n",
            "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.173316\n",
            "Train Epoch: 6 [17920/60032 (30%)]\tLoss: 0.166163\n",
            "Train Epoch: 6 [18560/60032 (31%)]\tLoss: 0.087246\n",
            "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.185980\n",
            "Train Epoch: 6 [19840/60032 (33%)]\tLoss: 0.117089\n",
            "Train Epoch: 6 [20480/60032 (34%)]\tLoss: 0.287187\n",
            "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.336806\n",
            "Train Epoch: 6 [21760/60032 (36%)]\tLoss: 0.077730\n",
            "Train Epoch: 6 [22400/60032 (37%)]\tLoss: 0.172918\n",
            "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.111289\n",
            "Train Epoch: 6 [23680/60032 (39%)]\tLoss: 0.193012\n",
            "Train Epoch: 6 [24320/60032 (41%)]\tLoss: 0.163906\n",
            "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.187509\n",
            "Train Epoch: 6 [25600/60032 (43%)]\tLoss: 0.121589\n",
            "Train Epoch: 6 [26240/60032 (44%)]\tLoss: 0.066833\n",
            "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.258450\n",
            "Train Epoch: 6 [27520/60032 (46%)]\tLoss: 0.219698\n",
            "Train Epoch: 6 [28160/60032 (47%)]\tLoss: 0.040842\n",
            "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.163001\n",
            "Train Epoch: 6 [29440/60032 (49%)]\tLoss: 0.128860\n",
            "Train Epoch: 6 [30080/60032 (50%)]\tLoss: 0.174516\n",
            "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.295337\n",
            "Train Epoch: 6 [31360/60032 (52%)]\tLoss: 0.116576\n",
            "Train Epoch: 6 [32000/60032 (53%)]\tLoss: 0.129392\n",
            "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.272873\n",
            "Train Epoch: 6 [33280/60032 (55%)]\tLoss: 0.171069\n",
            "Train Epoch: 6 [33920/60032 (57%)]\tLoss: 0.084507\n",
            "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.159216\n",
            "Train Epoch: 6 [35200/60032 (59%)]\tLoss: 0.078491\n",
            "Train Epoch: 6 [35840/60032 (60%)]\tLoss: 0.135174\n",
            "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.083802\n",
            "Train Epoch: 6 [37120/60032 (62%)]\tLoss: 0.140115\n",
            "Train Epoch: 6 [37760/60032 (63%)]\tLoss: 0.103262\n",
            "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.106866\n",
            "Train Epoch: 6 [39040/60032 (65%)]\tLoss: 0.062528\n",
            "Train Epoch: 6 [39680/60032 (66%)]\tLoss: 0.226298\n",
            "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.151920\n",
            "Train Epoch: 6 [40960/60032 (68%)]\tLoss: 0.070508\n",
            "Train Epoch: 6 [41600/60032 (69%)]\tLoss: 0.131918\n",
            "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.354989\n",
            "Train Epoch: 6 [42880/60032 (71%)]\tLoss: 0.116108\n",
            "Train Epoch: 6 [43520/60032 (72%)]\tLoss: 0.157842\n",
            "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.092239\n",
            "Train Epoch: 6 [44800/60032 (75%)]\tLoss: 0.080073\n",
            "Train Epoch: 6 [45440/60032 (76%)]\tLoss: 0.066709\n",
            "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.064104\n",
            "Train Epoch: 6 [46720/60032 (78%)]\tLoss: 0.133768\n",
            "Train Epoch: 6 [47360/60032 (79%)]\tLoss: 0.130757\n",
            "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.098512\n",
            "Train Epoch: 6 [48640/60032 (81%)]\tLoss: 0.419644\n",
            "Train Epoch: 6 [49280/60032 (82%)]\tLoss: 0.247662\n",
            "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.059927\n",
            "Train Epoch: 6 [50560/60032 (84%)]\tLoss: 0.143026\n",
            "Train Epoch: 6 [51200/60032 (85%)]\tLoss: 0.103520\n",
            "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.392840\n",
            "Train Epoch: 6 [52480/60032 (87%)]\tLoss: 0.282294\n",
            "Train Epoch: 6 [53120/60032 (88%)]\tLoss: 0.105724\n",
            "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.094779\n",
            "Train Epoch: 6 [54400/60032 (91%)]\tLoss: 0.058526\n",
            "Train Epoch: 6 [55040/60032 (92%)]\tLoss: 0.255506\n",
            "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.078047\n",
            "Train Epoch: 6 [56320/60032 (94%)]\tLoss: 0.064096\n",
            "Train Epoch: 6 [56960/60032 (95%)]\tLoss: 0.132563\n",
            "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.131495\n",
            "Train Epoch: 6 [58240/60032 (97%)]\tLoss: 0.121406\n",
            "Train Epoch: 6 [58880/60032 (98%)]\tLoss: 0.120680\n",
            "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.143455\n",
            "\n",
            "Test set: Average loss: 0.1452, Accuracy: 9577/10000 (96%)\n",
            "\n",
            "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.135182\n",
            "Train Epoch: 7 [640/60032 (1%)]\tLoss: 0.151866\n",
            "Train Epoch: 7 [1280/60032 (2%)]\tLoss: 0.136436\n",
            "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.057388\n",
            "Train Epoch: 7 [2560/60032 (4%)]\tLoss: 0.102769\n",
            "Train Epoch: 7 [3200/60032 (5%)]\tLoss: 0.195271\n",
            "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.074549\n",
            "Train Epoch: 7 [4480/60032 (7%)]\tLoss: 0.062742\n",
            "Train Epoch: 7 [5120/60032 (9%)]\tLoss: 0.057787\n",
            "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.373536\n",
            "Train Epoch: 7 [6400/60032 (11%)]\tLoss: 0.104477\n",
            "Train Epoch: 7 [7040/60032 (12%)]\tLoss: 0.075166\n",
            "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.088306\n",
            "Train Epoch: 7 [8320/60032 (14%)]\tLoss: 0.069394\n",
            "Train Epoch: 7 [8960/60032 (15%)]\tLoss: 0.100376\n",
            "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.091116\n",
            "Train Epoch: 7 [10240/60032 (17%)]\tLoss: 0.091419\n",
            "Train Epoch: 7 [10880/60032 (18%)]\tLoss: 0.035829\n",
            "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.072836\n",
            "Train Epoch: 7 [12160/60032 (20%)]\tLoss: 0.127332\n",
            "Train Epoch: 7 [12800/60032 (21%)]\tLoss: 0.161855\n",
            "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.066086\n",
            "Train Epoch: 7 [14080/60032 (23%)]\tLoss: 0.131063\n",
            "Train Epoch: 7 [14720/60032 (25%)]\tLoss: 0.124118\n",
            "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.195303\n",
            "Train Epoch: 7 [16000/60032 (27%)]\tLoss: 0.143472\n",
            "Train Epoch: 7 [16640/60032 (28%)]\tLoss: 0.162836\n",
            "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.192718\n",
            "Train Epoch: 7 [17920/60032 (30%)]\tLoss: 0.091289\n",
            "Train Epoch: 7 [18560/60032 (31%)]\tLoss: 0.074630\n",
            "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.054641\n",
            "Train Epoch: 7 [19840/60032 (33%)]\tLoss: 0.225183\n",
            "Train Epoch: 7 [20480/60032 (34%)]\tLoss: 0.047583\n",
            "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.063063\n",
            "Train Epoch: 7 [21760/60032 (36%)]\tLoss: 0.151142\n",
            "Train Epoch: 7 [22400/60032 (37%)]\tLoss: 0.164766\n",
            "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.162474\n",
            "Train Epoch: 7 [23680/60032 (39%)]\tLoss: 0.084060\n",
            "Train Epoch: 7 [24320/60032 (41%)]\tLoss: 0.059223\n",
            "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.150194\n",
            "Train Epoch: 7 [25600/60032 (43%)]\tLoss: 0.118478\n",
            "Train Epoch: 7 [26240/60032 (44%)]\tLoss: 0.012789\n",
            "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.144688\n",
            "Train Epoch: 7 [27520/60032 (46%)]\tLoss: 0.222231\n",
            "Train Epoch: 7 [28160/60032 (47%)]\tLoss: 0.069504\n",
            "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.039505\n",
            "Train Epoch: 7 [29440/60032 (49%)]\tLoss: 0.209513\n",
            "Train Epoch: 7 [30080/60032 (50%)]\tLoss: 0.281905\n",
            "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.169849\n",
            "Train Epoch: 7 [31360/60032 (52%)]\tLoss: 0.121481\n",
            "Train Epoch: 7 [32000/60032 (53%)]\tLoss: 0.129022\n",
            "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.056230\n",
            "Train Epoch: 7 [33280/60032 (55%)]\tLoss: 0.086364\n",
            "Train Epoch: 7 [33920/60032 (57%)]\tLoss: 0.140788\n",
            "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.120152\n",
            "Train Epoch: 7 [35200/60032 (59%)]\tLoss: 0.080473\n",
            "Train Epoch: 7 [35840/60032 (60%)]\tLoss: 0.099317\n",
            "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.145395\n",
            "Train Epoch: 7 [37120/60032 (62%)]\tLoss: 0.127186\n",
            "Train Epoch: 7 [37760/60032 (63%)]\tLoss: 0.184066\n",
            "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.424722\n",
            "Train Epoch: 7 [39040/60032 (65%)]\tLoss: 0.077351\n",
            "Train Epoch: 7 [39680/60032 (66%)]\tLoss: 0.073521\n",
            "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.129815\n",
            "Train Epoch: 7 [40960/60032 (68%)]\tLoss: 0.105949\n",
            "Train Epoch: 7 [41600/60032 (69%)]\tLoss: 0.116594\n",
            "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.115371\n",
            "Train Epoch: 7 [42880/60032 (71%)]\tLoss: 0.186970\n",
            "Train Epoch: 7 [43520/60032 (72%)]\tLoss: 0.105743\n",
            "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.097843\n",
            "Train Epoch: 7 [44800/60032 (75%)]\tLoss: 0.150414\n",
            "Train Epoch: 7 [45440/60032 (76%)]\tLoss: 0.070855\n",
            "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.123109\n",
            "Train Epoch: 7 [46720/60032 (78%)]\tLoss: 0.048025\n",
            "Train Epoch: 7 [47360/60032 (79%)]\tLoss: 0.111979\n",
            "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.120260\n",
            "Train Epoch: 7 [48640/60032 (81%)]\tLoss: 0.053983\n",
            "Train Epoch: 7 [49280/60032 (82%)]\tLoss: 0.124351\n",
            "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.146113\n",
            "Train Epoch: 7 [50560/60032 (84%)]\tLoss: 0.129525\n",
            "Train Epoch: 7 [51200/60032 (85%)]\tLoss: 0.044389\n",
            "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.132415\n",
            "Train Epoch: 7 [52480/60032 (87%)]\tLoss: 0.070121\n",
            "Train Epoch: 7 [53120/60032 (88%)]\tLoss: 0.288250\n",
            "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.089510\n",
            "Train Epoch: 7 [54400/60032 (91%)]\tLoss: 0.032601\n",
            "Train Epoch: 7 [55040/60032 (92%)]\tLoss: 0.047054\n",
            "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.178916\n",
            "Train Epoch: 7 [56320/60032 (94%)]\tLoss: 0.139041\n",
            "Train Epoch: 7 [56960/60032 (95%)]\tLoss: 0.165898\n",
            "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.074544\n",
            "Train Epoch: 7 [58240/60032 (97%)]\tLoss: 0.077624\n",
            "Train Epoch: 7 [58880/60032 (98%)]\tLoss: 0.151630\n",
            "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.068818\n",
            "\n",
            "Test set: Average loss: 0.1315, Accuracy: 9617/10000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.065677\n",
            "Train Epoch: 8 [640/60032 (1%)]\tLoss: 0.148889\n",
            "Train Epoch: 8 [1280/60032 (2%)]\tLoss: 0.080893\n",
            "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.076046\n",
            "Train Epoch: 8 [2560/60032 (4%)]\tLoss: 0.167141\n",
            "Train Epoch: 8 [3200/60032 (5%)]\tLoss: 0.093265\n",
            "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.055351\n",
            "Train Epoch: 8 [4480/60032 (7%)]\tLoss: 0.198213\n",
            "Train Epoch: 8 [5120/60032 (9%)]\tLoss: 0.110542\n",
            "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.122097\n",
            "Train Epoch: 8 [6400/60032 (11%)]\tLoss: 0.171013\n",
            "Train Epoch: 8 [7040/60032 (12%)]\tLoss: 0.374627\n",
            "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.111649\n",
            "Train Epoch: 8 [8320/60032 (14%)]\tLoss: 0.057369\n",
            "Train Epoch: 8 [8960/60032 (15%)]\tLoss: 0.322805\n",
            "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.137502\n",
            "Train Epoch: 8 [10240/60032 (17%)]\tLoss: 0.067202\n",
            "Train Epoch: 8 [10880/60032 (18%)]\tLoss: 0.059840\n",
            "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.053047\n",
            "Train Epoch: 8 [12160/60032 (20%)]\tLoss: 0.124975\n",
            "Train Epoch: 8 [12800/60032 (21%)]\tLoss: 0.068246\n",
            "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.062594\n",
            "Train Epoch: 8 [14080/60032 (23%)]\tLoss: 0.115440\n",
            "Train Epoch: 8 [14720/60032 (25%)]\tLoss: 0.070013\n",
            "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.085488\n",
            "Train Epoch: 8 [16000/60032 (27%)]\tLoss: 0.286904\n",
            "Train Epoch: 8 [16640/60032 (28%)]\tLoss: 0.056551\n",
            "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.103778\n",
            "Train Epoch: 8 [17920/60032 (30%)]\tLoss: 0.167648\n",
            "Train Epoch: 8 [18560/60032 (31%)]\tLoss: 0.124912\n",
            "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.136744\n",
            "Train Epoch: 8 [19840/60032 (33%)]\tLoss: 0.204416\n",
            "Train Epoch: 8 [20480/60032 (34%)]\tLoss: 0.072913\n",
            "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.093132\n",
            "Train Epoch: 8 [21760/60032 (36%)]\tLoss: 0.168502\n",
            "Train Epoch: 8 [22400/60032 (37%)]\tLoss: 0.078253\n",
            "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.031783\n",
            "Train Epoch: 8 [23680/60032 (39%)]\tLoss: 0.033297\n",
            "Train Epoch: 8 [24320/60032 (41%)]\tLoss: 0.057042\n",
            "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.137087\n",
            "Train Epoch: 8 [25600/60032 (43%)]\tLoss: 0.077088\n",
            "Train Epoch: 8 [26240/60032 (44%)]\tLoss: 0.055266\n",
            "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.172067\n",
            "Train Epoch: 8 [27520/60032 (46%)]\tLoss: 0.106673\n",
            "Train Epoch: 8 [28160/60032 (47%)]\tLoss: 0.056106\n",
            "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.188475\n",
            "Train Epoch: 8 [29440/60032 (49%)]\tLoss: 0.270789\n",
            "Train Epoch: 8 [30080/60032 (50%)]\tLoss: 0.189891\n",
            "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.056950\n",
            "Train Epoch: 8 [31360/60032 (52%)]\tLoss: 0.274009\n",
            "Train Epoch: 8 [32000/60032 (53%)]\tLoss: 0.065227\n",
            "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.064538\n",
            "Train Epoch: 8 [33280/60032 (55%)]\tLoss: 0.124059\n",
            "Train Epoch: 8 [33920/60032 (57%)]\tLoss: 0.160329\n",
            "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.063688\n",
            "Train Epoch: 8 [35200/60032 (59%)]\tLoss: 0.140033\n",
            "Train Epoch: 8 [35840/60032 (60%)]\tLoss: 0.114405\n",
            "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.077373\n",
            "Train Epoch: 8 [37120/60032 (62%)]\tLoss: 0.126993\n",
            "Train Epoch: 8 [37760/60032 (63%)]\tLoss: 0.224920\n",
            "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.154187\n",
            "Train Epoch: 8 [39040/60032 (65%)]\tLoss: 0.144140\n",
            "Train Epoch: 8 [39680/60032 (66%)]\tLoss: 0.150628\n",
            "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.158121\n",
            "Train Epoch: 8 [40960/60032 (68%)]\tLoss: 0.091867\n",
            "Train Epoch: 8 [41600/60032 (69%)]\tLoss: 0.218355\n",
            "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.160290\n",
            "Train Epoch: 8 [42880/60032 (71%)]\tLoss: 0.131203\n",
            "Train Epoch: 8 [43520/60032 (72%)]\tLoss: 0.044088\n",
            "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.071225\n",
            "Train Epoch: 8 [44800/60032 (75%)]\tLoss: 0.246906\n",
            "Train Epoch: 8 [45440/60032 (76%)]\tLoss: 0.346337\n",
            "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.039245\n",
            "Train Epoch: 8 [46720/60032 (78%)]\tLoss: 0.088932\n",
            "Train Epoch: 8 [47360/60032 (79%)]\tLoss: 0.138715\n",
            "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.174456\n",
            "Train Epoch: 8 [48640/60032 (81%)]\tLoss: 0.123875\n",
            "Train Epoch: 8 [49280/60032 (82%)]\tLoss: 0.125833\n",
            "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.093205\n",
            "Train Epoch: 8 [50560/60032 (84%)]\tLoss: 0.052882\n",
            "Train Epoch: 8 [51200/60032 (85%)]\tLoss: 0.053356\n",
            "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.102226\n",
            "Train Epoch: 8 [52480/60032 (87%)]\tLoss: 0.254533\n",
            "Train Epoch: 8 [53120/60032 (88%)]\tLoss: 0.143404\n",
            "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.134531\n",
            "Train Epoch: 8 [54400/60032 (91%)]\tLoss: 0.103584\n",
            "Train Epoch: 8 [55040/60032 (92%)]\tLoss: 0.222141\n",
            "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.134924\n",
            "Train Epoch: 8 [56320/60032 (94%)]\tLoss: 0.060914\n",
            "Train Epoch: 8 [56960/60032 (95%)]\tLoss: 0.204046\n",
            "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.159879\n",
            "Train Epoch: 8 [58240/60032 (97%)]\tLoss: 0.052744\n",
            "Train Epoch: 8 [58880/60032 (98%)]\tLoss: 0.093195\n",
            "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.119813\n",
            "\n",
            "Test set: Average loss: 0.1257, Accuracy: 9626/10000 (96%)\n",
            "\n",
            "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.043633\n",
            "Train Epoch: 9 [640/60032 (1%)]\tLoss: 0.035205\n",
            "Train Epoch: 9 [1280/60032 (2%)]\tLoss: 0.127312\n",
            "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.067129\n",
            "Train Epoch: 9 [2560/60032 (4%)]\tLoss: 0.031652\n",
            "Train Epoch: 9 [3200/60032 (5%)]\tLoss: 0.104728\n",
            "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.130032\n",
            "Train Epoch: 9 [4480/60032 (7%)]\tLoss: 0.062465\n",
            "Train Epoch: 9 [5120/60032 (9%)]\tLoss: 0.216787\n",
            "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.105690\n",
            "Train Epoch: 9 [6400/60032 (11%)]\tLoss: 0.067072\n",
            "Train Epoch: 9 [7040/60032 (12%)]\tLoss: 0.086106\n",
            "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.049651\n",
            "Train Epoch: 9 [8320/60032 (14%)]\tLoss: 0.190786\n",
            "Train Epoch: 9 [8960/60032 (15%)]\tLoss: 0.170141\n",
            "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.028448\n",
            "Train Epoch: 9 [10240/60032 (17%)]\tLoss: 0.198345\n",
            "Train Epoch: 9 [10880/60032 (18%)]\tLoss: 0.225126\n",
            "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.170951\n",
            "Train Epoch: 9 [12160/60032 (20%)]\tLoss: 0.115788\n",
            "Train Epoch: 9 [12800/60032 (21%)]\tLoss: 0.109191\n",
            "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.153691\n",
            "Train Epoch: 9 [14080/60032 (23%)]\tLoss: 0.069006\n",
            "Train Epoch: 9 [14720/60032 (25%)]\tLoss: 0.070297\n",
            "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.079960\n",
            "Train Epoch: 9 [16000/60032 (27%)]\tLoss: 0.165552\n",
            "Train Epoch: 9 [16640/60032 (28%)]\tLoss: 0.152860\n",
            "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.144551\n",
            "Train Epoch: 9 [17920/60032 (30%)]\tLoss: 0.156970\n",
            "Train Epoch: 9 [18560/60032 (31%)]\tLoss: 0.072859\n",
            "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.120385\n",
            "Train Epoch: 9 [19840/60032 (33%)]\tLoss: 0.041526\n",
            "Train Epoch: 9 [20480/60032 (34%)]\tLoss: 0.165385\n",
            "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.043062\n",
            "Train Epoch: 9 [21760/60032 (36%)]\tLoss: 0.078158\n",
            "Train Epoch: 9 [22400/60032 (37%)]\tLoss: 0.054449\n",
            "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.085261\n",
            "Train Epoch: 9 [23680/60032 (39%)]\tLoss: 0.052962\n",
            "Train Epoch: 9 [24320/60032 (41%)]\tLoss: 0.090885\n",
            "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.055979\n",
            "Train Epoch: 9 [25600/60032 (43%)]\tLoss: 0.065262\n",
            "Train Epoch: 9 [26240/60032 (44%)]\tLoss: 0.081973\n",
            "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.195247\n",
            "Train Epoch: 9 [27520/60032 (46%)]\tLoss: 0.104328\n",
            "Train Epoch: 9 [28160/60032 (47%)]\tLoss: 0.095311\n",
            "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.109646\n",
            "Train Epoch: 9 [29440/60032 (49%)]\tLoss: 0.084601\n",
            "Train Epoch: 9 [30080/60032 (50%)]\tLoss: 0.128154\n",
            "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.065456\n",
            "Train Epoch: 9 [31360/60032 (52%)]\tLoss: 0.033144\n",
            "Train Epoch: 9 [32000/60032 (53%)]\tLoss: 0.049191\n",
            "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.039093\n",
            "Train Epoch: 9 [33280/60032 (55%)]\tLoss: 0.144935\n",
            "Train Epoch: 9 [33920/60032 (57%)]\tLoss: 0.049381\n",
            "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.076351\n",
            "Train Epoch: 9 [35200/60032 (59%)]\tLoss: 0.088077\n",
            "Train Epoch: 9 [35840/60032 (60%)]\tLoss: 0.063071\n",
            "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.026124\n",
            "Train Epoch: 9 [37120/60032 (62%)]\tLoss: 0.033032\n",
            "Train Epoch: 9 [37760/60032 (63%)]\tLoss: 0.060115\n",
            "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.136589\n",
            "Train Epoch: 9 [39040/60032 (65%)]\tLoss: 0.133411\n",
            "Train Epoch: 9 [39680/60032 (66%)]\tLoss: 0.050361\n",
            "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.068408\n",
            "Train Epoch: 9 [40960/60032 (68%)]\tLoss: 0.081327\n",
            "Train Epoch: 9 [41600/60032 (69%)]\tLoss: 0.143364\n",
            "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.126337\n",
            "Train Epoch: 9 [42880/60032 (71%)]\tLoss: 0.170972\n",
            "Train Epoch: 9 [43520/60032 (72%)]\tLoss: 0.088350\n",
            "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.197318\n",
            "Train Epoch: 9 [44800/60032 (75%)]\tLoss: 0.068470\n",
            "Train Epoch: 9 [45440/60032 (76%)]\tLoss: 0.055007\n",
            "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.078719\n",
            "Train Epoch: 9 [46720/60032 (78%)]\tLoss: 0.099339\n",
            "Train Epoch: 9 [47360/60032 (79%)]\tLoss: 0.028216\n",
            "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.063415\n",
            "Train Epoch: 9 [48640/60032 (81%)]\tLoss: 0.081967\n",
            "Train Epoch: 9 [49280/60032 (82%)]\tLoss: 0.103481\n",
            "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.163556\n",
            "Train Epoch: 9 [50560/60032 (84%)]\tLoss: 0.156491\n",
            "Train Epoch: 9 [51200/60032 (85%)]\tLoss: 0.133811\n",
            "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.073265\n",
            "Train Epoch: 9 [52480/60032 (87%)]\tLoss: 0.055218\n",
            "Train Epoch: 9 [53120/60032 (88%)]\tLoss: 0.209990\n",
            "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.045508\n",
            "Train Epoch: 9 [54400/60032 (91%)]\tLoss: 0.081024\n",
            "Train Epoch: 9 [55040/60032 (92%)]\tLoss: 0.048262\n",
            "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.084398\n",
            "Train Epoch: 9 [56320/60032 (94%)]\tLoss: 0.022310\n",
            "Train Epoch: 9 [56960/60032 (95%)]\tLoss: 0.032487\n",
            "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.132078\n",
            "Train Epoch: 9 [58240/60032 (97%)]\tLoss: 0.084577\n",
            "Train Epoch: 9 [58880/60032 (98%)]\tLoss: 0.033183\n",
            "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.118170\n",
            "\n",
            "Test set: Average loss: 0.1156, Accuracy: 9663/10000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.135384\n",
            "Train Epoch: 10 [640/60032 (1%)]\tLoss: 0.051371\n",
            "Train Epoch: 10 [1280/60032 (2%)]\tLoss: 0.190999\n",
            "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.029779\n",
            "Train Epoch: 10 [2560/60032 (4%)]\tLoss: 0.037408\n",
            "Train Epoch: 10 [3200/60032 (5%)]\tLoss: 0.135455\n",
            "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.131916\n",
            "Train Epoch: 10 [4480/60032 (7%)]\tLoss: 0.032726\n",
            "Train Epoch: 10 [5120/60032 (9%)]\tLoss: 0.067895\n",
            "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.053659\n",
            "Train Epoch: 10 [6400/60032 (11%)]\tLoss: 0.077732\n",
            "Train Epoch: 10 [7040/60032 (12%)]\tLoss: 0.027862\n",
            "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.330603\n",
            "Train Epoch: 10 [8320/60032 (14%)]\tLoss: 0.125169\n",
            "Train Epoch: 10 [8960/60032 (15%)]\tLoss: 0.077548\n",
            "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.136963\n",
            "Train Epoch: 10 [10240/60032 (17%)]\tLoss: 0.038073\n",
            "Train Epoch: 10 [10880/60032 (18%)]\tLoss: 0.029222\n",
            "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.099027\n",
            "Train Epoch: 10 [12160/60032 (20%)]\tLoss: 0.086867\n",
            "Train Epoch: 10 [12800/60032 (21%)]\tLoss: 0.059937\n",
            "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.079621\n",
            "Train Epoch: 10 [14080/60032 (23%)]\tLoss: 0.223687\n",
            "Train Epoch: 10 [14720/60032 (25%)]\tLoss: 0.080653\n",
            "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.048582\n",
            "Train Epoch: 10 [16000/60032 (27%)]\tLoss: 0.132691\n",
            "Train Epoch: 10 [16640/60032 (28%)]\tLoss: 0.086237\n",
            "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.223127\n",
            "Train Epoch: 10 [17920/60032 (30%)]\tLoss: 0.233298\n",
            "Train Epoch: 10 [18560/60032 (31%)]\tLoss: 0.055328\n",
            "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.090380\n",
            "Train Epoch: 10 [19840/60032 (33%)]\tLoss: 0.027619\n",
            "Train Epoch: 10 [20480/60032 (34%)]\tLoss: 0.167188\n",
            "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.062808\n",
            "Train Epoch: 10 [21760/60032 (36%)]\tLoss: 0.047036\n",
            "Train Epoch: 10 [22400/60032 (37%)]\tLoss: 0.085691\n",
            "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.114309\n",
            "Train Epoch: 10 [23680/60032 (39%)]\tLoss: 0.059233\n",
            "Train Epoch: 10 [24320/60032 (41%)]\tLoss: 0.085992\n",
            "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.163074\n",
            "Train Epoch: 10 [25600/60032 (43%)]\tLoss: 0.026258\n",
            "Train Epoch: 10 [26240/60032 (44%)]\tLoss: 0.095437\n",
            "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.045312\n",
            "Train Epoch: 10 [27520/60032 (46%)]\tLoss: 0.040922\n",
            "Train Epoch: 10 [28160/60032 (47%)]\tLoss: 0.047934\n",
            "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.162295\n",
            "Train Epoch: 10 [29440/60032 (49%)]\tLoss: 0.136256\n",
            "Train Epoch: 10 [30080/60032 (50%)]\tLoss: 0.049922\n",
            "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.091455\n",
            "Train Epoch: 10 [31360/60032 (52%)]\tLoss: 0.120935\n",
            "Train Epoch: 10 [32000/60032 (53%)]\tLoss: 0.193379\n",
            "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.021140\n",
            "Train Epoch: 10 [33280/60032 (55%)]\tLoss: 0.112498\n",
            "Train Epoch: 10 [33920/60032 (57%)]\tLoss: 0.088101\n",
            "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.141678\n",
            "Train Epoch: 10 [35200/60032 (59%)]\tLoss: 0.177045\n",
            "Train Epoch: 10 [35840/60032 (60%)]\tLoss: 0.119974\n",
            "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.193482\n",
            "Train Epoch: 10 [37120/60032 (62%)]\tLoss: 0.261873\n",
            "Train Epoch: 10 [37760/60032 (63%)]\tLoss: 0.135245\n",
            "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.096033\n",
            "Train Epoch: 10 [39040/60032 (65%)]\tLoss: 0.060965\n",
            "Train Epoch: 10 [39680/60032 (66%)]\tLoss: 0.102301\n",
            "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.152887\n",
            "Train Epoch: 10 [40960/60032 (68%)]\tLoss: 0.057782\n",
            "Train Epoch: 10 [41600/60032 (69%)]\tLoss: 0.045418\n",
            "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.082214\n",
            "Train Epoch: 10 [42880/60032 (71%)]\tLoss: 0.055542\n",
            "Train Epoch: 10 [43520/60032 (72%)]\tLoss: 0.253563\n",
            "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.100605\n",
            "Train Epoch: 10 [44800/60032 (75%)]\tLoss: 0.036026\n",
            "Train Epoch: 10 [45440/60032 (76%)]\tLoss: 0.065976\n",
            "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.055047\n",
            "Train Epoch: 10 [46720/60032 (78%)]\tLoss: 0.055193\n",
            "Train Epoch: 10 [47360/60032 (79%)]\tLoss: 0.082746\n",
            "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.089039\n",
            "Train Epoch: 10 [48640/60032 (81%)]\tLoss: 0.142482\n",
            "Train Epoch: 10 [49280/60032 (82%)]\tLoss: 0.018484\n",
            "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.061793\n",
            "Train Epoch: 10 [50560/60032 (84%)]\tLoss: 0.096551\n",
            "Train Epoch: 10 [51200/60032 (85%)]\tLoss: 0.066852\n",
            "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.065532\n",
            "Train Epoch: 10 [52480/60032 (87%)]\tLoss: 0.057970\n",
            "Train Epoch: 10 [53120/60032 (88%)]\tLoss: 0.118211\n",
            "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.122786\n",
            "Train Epoch: 10 [54400/60032 (91%)]\tLoss: 0.078336\n",
            "Train Epoch: 10 [55040/60032 (92%)]\tLoss: 0.106299\n",
            "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.024387\n",
            "Train Epoch: 10 [56320/60032 (94%)]\tLoss: 0.083326\n",
            "Train Epoch: 10 [56960/60032 (95%)]\tLoss: 0.068246\n",
            "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.214633\n",
            "Train Epoch: 10 [58240/60032 (97%)]\tLoss: 0.116393\n",
            "Train Epoch: 10 [58880/60032 (98%)]\tLoss: 0.026166\n",
            "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.057837\n",
            "\n",
            "Test set: Average loss: 0.1114, Accuracy: 9667/10000 (97%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3iTpD33_82c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}